# Stage 1: Backend (FastAPI)
FROM nvidia/cuda:12.6.2-cudnn-devel-ubuntu22.04
# Set environment variable to avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Set working directory for backend
WORKDIR /backend

# Install necessary build tools for llama-cpp-python
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Install system dependencies
RUN apt-get update && apt-get install -y \
    software-properties-common \
    curl \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update \
    && apt-get install -y python3.12 python3.12-venv python3.12-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.12 as the default python version
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 \
    && update-alternatives --set python3 /usr/bin/python3.12

# Install pip
RUN curl -sS https://bootstrap.pypa.io/get-pip.py | python3

# Install Poetry
RUN pip install poetry

# Copy the Python project files
COPY backend/pyproject.toml backend/poetry.lock ./

# Install dependencies (without dev dependencies) with retry logic globally
RUN poetry install -E gpu

# Install llama-cpp-python with CUDA support
RUN CMAKE_ARGS="-DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS" pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --verbose

# Copy the rest of the backend project
COPY backend/ ./

# Install project itself
RUN poetry install -E gpu

# Set the PYTHONPATH environment variable
ENV PYTHONPATH="${PYTHONPATH}:/backend/actuosus_ai"

# Expose the port FastAPI will run on
EXPOSE 8000